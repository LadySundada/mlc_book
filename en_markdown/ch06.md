sensory receptors | 感受器


CHAPTER 6
第6章
**Sensory Components of Motor Control**
运动控制的感觉组成部分
*Concept: Touch, proprioception, and vision are important sensory components of motor control.*
概念：触觉、本体感觉和视觉是运动控制的重要感觉组成部分。
After completing this chapter, you will be able to
完成本章的学习后，你将能够

Describe the sensory receptors in the skin that provide tactile sensory information to 
the central nervous system
描述皮肤中为中枢神经系统提供触觉信息的感受器
Discuss several movement-related characteristics influenced by tactile sensory feedback
讨论受触觉反馈影响的几种运动相关的特征
Describe various types of sensory receptors that provide proprioception information 
to the central nervous system
描述为中枢神经系统提供本体感觉信息的各种类型的感受器
Describe several procedures researchers use to investigate the role of proprioception 
in motor control
描述研究人员为探究本体感觉在运动控制中的作用所使用的几种研究方法
Discuss several movement-related characteristics influenced by feedback from the proprioceptors
讨论受本体感觉反馈影响的几种运动相关的特征
Describe key anatomical components of the eye and neural pathways for vision
描述眼睛以及视觉神经通路的关键解剖学组成部分
Describe several procedures researchers use to investigate the role of vision in motor control
描述研究人员为探究视觉在运动控制中的作用所使用的几种研究方法
Discuss motor control issues related to the use of binocular and monocular vision, 
central and peripheral vision, the perception-action coupling of vision and movement, 
vision-based movement corrections, and the optical variable *tau*
讨论单目与双目视觉、中央与周围视觉、视觉与运动的知觉-动作耦合、基于视觉的运动纠正，以及光学变量tau在使用过程中的相关运动控制问题

**APPLICATION**
应用
When you reach for a glass of water to drink from it, the tactile (i.e., touch), proprioceptive, and visual ­sensory systems come into play as you carry out the action. Vision helps you locate the glass and grasp it with your hand and fingers. Touch and proprioception help you lift the glass, move it toward your mouth, and not have the glass slip out of your hand. Without the sensory information provided by these key sensory systems, you would have considerably more difficulty carrying out relatively simple tasks like drinking from a glass. You accomplish other every‑
day skills, such as putting your door key into the keyhole, maneuvering around people as you walk in a hallway, and driving your car with ease, because of the information that touch, proprioception, and vision provide your motor control system. Similarly, sport activities also require and benefit from the roles played by these same sensory systems. For example, to catch a ball, you must see where the ball is, time its arrival to your hand, position your hand in space, and then close your fingers around the ball when it is in your hand.
在你执行拿起水杯喝水这项运动技能的过程中，触觉、本体感觉和视觉的感觉系统都会发挥各自的作用。视觉帮助你定位到杯子的位置，并用手和手指将其抓住；触觉和本体感觉帮助你将杯子拿起来送到嘴边，并保证杯子不会从手中滑落。如果没有这些关键感觉系统提供的感觉信息，即便是像喝杯水这种相对简单的任务，执行起来都会面临相当大的困难。你之所以能够完成日常生活中的其他技能，如将钥匙插入锁孔和轻松地驾驶汽车，都是因为有触觉、本体感觉和视觉为你的运动控制系统提供的信息。类似地，体育活动也同样需要并受益于这些感觉系统的功能作用。例如，要接住球，你必须首先看到球的位置，判断球到手的时间，把手的位置摆好，然后当球到达手心时合上手指将其握住。
In all of these skill performance situations, practitioners can benefit from an understanding of the tactile, proprioception, and visual sensory systems 
in terms of their anatomical and physiological basis, how they influence the control of movement, and the limits they place on human motor skill performance. In the following discussion, we will consider each of these three sensory systems by addressing their anatomical and physiological basis and their relevance to the control of coordinated movement. The intent is to help practitioners establish a foundation on which they can build ­effective strategies to facilitate skill learning or rehabilitation for the people with whom they work.

**DISCUSSION**

A key feature of any theory of motor control is the role played by sensory information in controlling action. Of our various senses, touch, proprioception, and vision contribute to the motor control of skills in significant ways. In the study of human sensory physiology, touch and proprioception are included as senses in the *somatic* sensory system, whereas vision is the sense associated with the visual sensory system. In the following sections, we will look specifically at these three senses by describing their neural bases and the roles each plays in the control of ­human movement.

Before beginning the discussion of these sensory systems, it is important to point out that the limiting of this chapter to these three senses should not be interpreted as suggesting that they are the only senses ­involved in motor control. We know from the research literature (e.g., Huber, Stathopoulos, & ­Sussman, 2004) that auditory sensory information is especially important for speech production; and anecdotal evidence from skilled athletes describes the importance of auditory information for influencing their behavior, such as determining the ball flight characteristics of a batted ball in baseball and a serve or ground stroke in tennis. In addition, research (e.g., Guerraz & Day, 2005) has shown the important role of the vestibular system of the inner ear in the control of balance and possibly arm-trunk coordination during trunk-assisted reaching movements (Mars, ­Archambault, & Feldman, 2003), although both also involve the tactile, proprioception, and ­vision sensory systems. The vestibular system also seems to play a role in the representation of external space (Borel et al., 2014). However, for purposes of this chapter, which is to introduce you to the involvement of the sensory systems in motor control, we will limit our discussion to touch, proprioception, and vision.

**TOUCH AND MOTOR CONTROL**

Consider the variety of ways in which we involve our sense of touch when we perform motor skills. Skills that require us to manipulate an object (e.g., holding a 
fork, typing a text message, and picking up a ball) or person (e.g., wrestling, boxing, and tae kwon do) and to interact with natural features in our environment, such as walking barefoot on the beach, include the detection of specific characteristics of the object, person, or environment through tactile sensory receptors in our skin that are part of our somatic sensory system. But how is this sensory information used to help us perform these skills? To answer this question, we will first consider the neural basis for the detection of this type of sensory information and then describe what research has shown as some of the movement characteristics of motor skill performance that are influenced by tactile sensory information.

**Neural Basis of Touch**

When we touch something, *mechanoreceptors* in the skin activate to provide the CNS with information related to pain, temperature, and movement. These receptors, which are illustrated in figure 6.1, are located just below the skin surface in the dermis portion of the skin. As mechanoreceptors, these sensory receptors detect skin stretch and joint movement. The greatest concentration of these ­receptors is in the fingertips.

**The Role of Tactile Sensory Information 
in Motor Control**

Researchers generally agree that touch plays an im‑
portant role in the performance of a variety of types of motor skills and motor control processes. We will briefly consider five movement-related characteristics influenced by tactile sensory information the CNS receives from touch. First, a predominant characteristic is *movement accuracy,* which decreases when tactile information is not available, especially at the fingertips. Research has demonstrated poorer accuracy when tactile feedback is removed or minimized for several skills including pointing (Rao & 
Gordon, 2001), reaching and grasping ­(Gentilucci, Toni, Daprati, & ­Gangitano, 1997), typing on a ­keyboard (Gordon & Soechting, 1995; Rabin & Gordon, 2004), maintaining a precision grip (Fisher, Galea, Brown, & Lemon, 2002), rhythmically tapping a finger to an auditory stimulus (Pollok, MŸller, Ascherleben, Schnitzler, & Prinz, 2004), and playing a sequence of notes on a piano (Goebl & Palmer, 2008). In most of these studies, the researchers anesthetized the fingertips so that tactile afferent information would not be available, which provided the opportunity to compare movement accuracy to performance with no anesthesia. A different approach to determining the role of tactile afferent information in motor control is to add touch to the performance of an activity. For example, in the experiment by Rao and Gordon (2001), participants increased their pointing accuracy when they reproduced a pointing movement to a target they had touched compared to when they moved their arm to the target location without touching it. A slightly different approach revealed that participants made more accurate and more consistent reaches with the index finger on one hand to the unseen index finger on the other hand, when a brief vibrotactile stimulus was applied to the target index finger (Mikula et al., 2018).

*Movement consistency* is another movement characteristic influenced by tactile feedback, as shown by the Mikula et al. (2018) experiment. Other experiments by Gordon and colleagues (e.g., Gordon & Soechting, 1995; Rabin & Gordon, 2004) demonstrated this effect for keyboard typing by comparing typing ­performance before and after anesthetizing a finger. They showed that without tactile sensory feedback from the finger, not only did typing accuracy decrease, as described above, but movement consistency from one trial to another also decreased. Third, *movement timing* can be influenced by tactile feedback, particularly in rhythmic movements that involve intermittent contact with the environment, like juggling and locomotion (Ankarali, Sen, De, Okamura, & Cowan, 2014). For example, experiments by Zelaznik and colleagues have shown that including a tactile event (e.g., a velcro strip at the top of the circle) as a timing cue improved timing accuracy for continuous circle drawing when a criterion time for completing the circle was required (e.g., Studenka, Zelaznik, & Balasubramaniam, 2012).

Fourth, *movement force adjustments* while holding and using an object also depend on tactile feedback. For example, when you grasp a cup and lift it from a table to drink from it, you need to regulate the amount of grip force as you move the cup to your mouth and properly position the cup to drink from it. Evidence for the role played by tactile sensory feedback in adjusting grip forces during movement has been reported in several ­studies (e.g., Gysin, Kaminski, & Gordon, 2003; Nowak & Hermsdorfer, 2003; White, 2015; White et al., 2018). These researchers have shown that the sensory feedback from the grasping fingertips intermittently updates the movement command center in the CNS (as illustrated in the closed-loop control system in figure 5.3 in chapter 5) to adjust grip forces as ­necessary.

Finally, Rao and Gordon (2001) concluded that ­tactile feedback could be used to improve the use of proprioceptive feedback to *estimate* *movement distance* when the beginning and end of a pointing movement involved touching a surface.

**PROPRIOCEPTION 
AND MOTOR CONTROL**

**Proprioception** refers to our sensation and perception of limb, trunk, and head position and movement.1 Although it is often overlooked as one of our basic senses, proprioception is sensory information transmitted to the central nervous system about such movement characteristics as direction, location in space, velocity, and muscle activation. In closed-loop models of movement control, proprioceptive feedback plays a significant role, whereas in open-loop models, central commands control movement without involving proprioceptive feedback. Questions about whether we can control movements without proprioceptive feedback, and what role ­proprioceptive feedback plays in the control of ­coordinated movement, have intrigued movement scientists for many years (see ­Willingham, 1998, p. 574 for a brief historical review).

Researchers have taken a variety of experimental approaches to determine the role of proprioception in controlling coordinated movement. We discuss a few of these to introduce you to the current thinking about this issue. However, before considering proprioception’s role in motor control, we will take a brief look at the neural basis of proprioception.

**The Neural Basis of Proprioception**

The CNS receives proprioceptive ­information from afferent neural pathways that begin in **pro­pri­oceptors**, which are sensory neurons located in the muscles, tendons, ligaments, and joints. These neurons pick up information about body and limb position and changes in position. There are several types of proprioceptors, each of which detects ­specific characteristics of body and limb position and movement. We focus on the muscle spindles, which detect changes in muscle length, the Golgi-tendon organs, which detect changes in muscle tension, and the joint receptors, which detect changes in joint movement.

***Muscle spindles.***Proprioceptors called **muscle spindles** lie within the fibers of most skeletal muscles. The muscles that control the eyes, hands, and neck have the greatest number of muscle spindles, allowing these body parts to be controlled with great precision or, in the case of the neck, allowing precise coordination between the eyes and the head and the rest of the body. As illustrated in figure 6.2, 
they are specialized muscle fibers that contain a capsule with both sensory receptors and muscle fibers, known as intrafusal muscle fibers. Spindles lie in parallel with extrafusal muscle fibers and are attached directly to the muscle sheath. Type Ia axons, which conduct nerve impulses very rapidly, are the primary sensory receptors in the muscle spindle. These axons wrap around the middle region of intrafusal muscle fibers and detect *changes in muscle length and velocity.* As mechanoreceptors, the sensory ­receptors of the muscle spindles respond to changes in muscle length which cause a mechanical deformation of the receptors and result in a nerve impulse. Within the muscle spindle are stretch receptors that detect the amount of stretch as well as the speed of the stretch. When a muscle stretches, the nerve ­impulse rate from the muscle spindle increases; when the muscle shortens, the rate reduces. Muscle spindles also encode joint angle when the muscles are relaxed, because of a linear relation between joint angle and firing rate, but not when the muscles actively hold a joint position (Macefield & Knellwolf, 2018). According to ­Macefield (2005) muscle spindles detect changes in joint angle in one axis, which provide the basis for the muscle spindles distributed throughout the muscles that act on a joint to provide feedback about complex patterns of muscle-length changes.

The nerve impulses from the muscle spindle travel along afferent nerve fibers to the dorsal root of the spinal cord. In the spinal cord, these afferent fibers divide into branches that allow the nerve impulses to do any of several things, depending on the movement situation. If the movement is a simple ­reflex movement, such as a knee jerk, the impulse follows a branch that synapses with an alpha motor neuron in the ventral horn of the spinal cord that ­activates the agonist muscle to produce the reflex movement. (see Figure 6.3 for a simplified diagram of the knee-jerk reflex). Another branch synapses with inhibitory interneurons that inhibit activity of antagonistic muscles. A third branch synapses with motor neurons that activate synergistic muscles associated with the intended movement. The fourth branch continues up the spinal cord to the brainstem where it synapses with interneurons to connect with areas of the brain responsible for motor control.

In the control of voluntary movement the muscle spindle serves as a feedback mechanism. For many years, researchers gave the muscle spindles a minor role in providing feedback about limb position and movement. However, since the early 1970s, this view has changed dramatically as research has demonstrated through experiments involving muscle vibration and fatigue that the muscle spindles are the *most important source* of proprioceptive ­information to the CNS about the *limb movement characteristics of ­position, direction, and velocity, as well as a sense of effort* (for a brief overview of this history, see Collins, Refshauge, Todd, & Gandevia, 2005; Proske, 2015; Proske & Gandevia, 2009). The CNS uses the limb movement feedback in the control of a discrete movement that must stop at a specific location in space and in the control of ongoing movements to ensure the spatial and temporal accuracy of the movements. In addition some researchers (e.g., Albert et al., 2005) contend that the feedback from muscle spindles also assists the CNS in movement planning.

***Golgi-tendon organs (GTOs).***As illustrated in figure 6.2 the **Golgi-tendon organs (GTOs)** are ­located in the skeletal muscle near the insertion of the tendons into the muscle. The GTOs consist of type Ib sensory axons that detect *changes in ­muscle tension, or force;* they are poor detectors of changes in muscle length. These sensory receptors respond to any tension created by the contracting muscle to which it is attached. The axons of the GTOs enter the dorsal horn of the spinal cord and synapse on interneurons in the ventral horn, where the interneurons synapse with alpha motor neurons that can cause inhibition of the contracting muscle and ­related synergistic muscles and that can stimulate the motor neurons of antagonistic muscles.

***Joint receptors.***Several types of proprioceptors are located in the joint capsule and ligaments; together these are referred to as **joint receptors**. The specific identity of these receptors is an issue of some debate among neuroscientists (e.g., ­Collins, Ref­shauge, Todd, & Gandevia, 2005). However, there is ­agree­ment that some are the *Ruffini endings, Pacinian corpuscles,* and *Golgi-like* receptors (Macefield, 2005). Not all joints contain the same types of receptors. As a result, it is common to see researchers refer to “joint receptors” as a collective term rather than specify the individual receptors within the joint. As mechanoreceptors, the joint receptors respond to changes in force and rotation applied to the joint and to changes in joint movement angle, especially at the extreme limits of angular movement or joint positions.

**Investigating the Role of Proprioception in Motor Control**

Proprioception is an important source of feedback. When performance of an action is under closed-loop control, proprioceptive information allows us to make movement corrections as we move. When an action is under open-loop control, as in a rapid, ballistic movement, proprioceptive feedback is available, but we cannot make movement corrections as we move because of time limitations.

Researchers have used several techniques to investigate the role of proprioception in the control of movement. We will consider three techniques in this discussion. Two of the techniques involve the observation of movement after **deafferentation** in some way. This means that the proprioceptive afferent pathways to the CNS are not available. The third involves the observation of movement while a tendon of a muscle involved in the control of a movement is vibrated, which distorts the pro‑prioceptive feedback that is normally received from the muscle and tendon proprioceptors.

**Deafferentation Techniques**

***Surgical deafferentation.***One method used to investigate the role of proprioception in the control of movement involves the ­observation of movement of animals or humans following surgical deafferentation, which means that the afferent neural pathways associated with the movements of interest have been surgically ­severed or removed. Several studies have been reported in which a surgical deafferentation procedure was used with monkeys. For example, two of the most well-known sets of experiments involving animals were reported in the 1960s and 1970s by Taub and Berman (1963, 1968) and Bizzi and his colleagues (e.g., Bizzi & Polit, 1979; Polit & Bizzi, 1978). These studies involved observing monkeys performing either typical activities, such as grooming and climbing, or newly learned movements, such as pointing to a light without vision of the arm and hand, before and after surgical deafferentation. Results showed that although the deafferented monkeys could still perform the skills, the degree of movement precision was notably less than it had been with proprioceptive feedback available.

Surgically deafferenting human subjects for experimental purposes is not possible, for obvious reasons. However, some people are surgically deafferented ­because of certain trauma- or disease-­related problems. For example, rheumatoid arthritis patients who have had finger *joint replacement* ­surgery have no joint receptors available. The most commonly cited example of using this approach to the study of pro‑prioception is an experiment done many years ago by Kelso, Holt, and Flatt (1980). On each trial, participants moved their fingers to a criterion finger position or a criterion ­distance, returned their fingers to a new starting point, and then attempted to reproduce the criterion position or distance. ­Results indicated that the patients had ­little difficulty in accurately reproducing the criterion finger *position* from a starting point that was different from the original starting point. However, they did have problems reproducing the movement *distance* from these new starting points.

***Deafferentation due to sensory neuropathy.***The observation of movement characteristics of people who have a sensory neuropathy (also called a peripheral neuropathy) involving a limb provides a nonsurgical technique for investigating deafferented humans. For these people, peripheral afferent nerves in various parts of the body are not functioning properly. In some cases, the efferent motor pathways are intact. 

To demonstrate how this type of deafferentation has helped identify some of the roles proprioception plays in motor control, we will consider a few examples of experiments that have compared participants with and without sensory neuropathy performing a variety of tasks. One of the early studies reporting the use of this research strategy was an experiment by Blouin et al. (1993). They compared a sensory neuropathy patient with normal participants on a pointing task involving an arm moving a pointer. On some trials, participants could see the task environment, whereas on other trials, they performed without this visual information available. Results, shown in figure 6.4, 
were that with vision, the patient performed as ­accurately as the normal participants. However, without vision of either the environment or the arm while moving, the deafferented patient consistently undershot the target. Thus, without visual feedback, the deafferented patient was not able to reproduce movement accurately to a specific location in space.

More recently, additional research has ­confirmed and extended the Blouin et al. (1993) results. For example, in one study (Messier, Adamovich, ­Berkinblit, Tunik, & Poizner, 2003) a sensory neuropathy patient (identified as C. F.) and five neurologically normal adults were asked to make reaching movements ­without vision to remembered targets in front of them in a smooth, continuous motion. C. F. made large limb movement spatial errors and did not produce smooth and simultaneous movements at the shoulder and elbow joints at slow, preferred, and fast speeds during movement.

The third example is an experiment involving a more complex task (Spencer, Ivry, Cattaert, & Semjen, 2005). Two ­sensory neuropathy patients and three control participants simultaneously drew circles with each hand for 15 sec per trial at varying speeds with full, partial, and no vision of their hands. The notable performance differences were that the sizes (i.e., amplitudes) and shapes of the circles drawn by each arm of the patients were less similar to each other than were those drawn by the non-neuropathy participants. The patients’ circles tended to drift on each successive repetition during a trial. Notably, the temporal aspect of the two-arm coordination (i.e., the amount of time to draw one circle) and the relative phase coordination were not different between the two groups of participants.

In the most recent example with three sensory neuropathy patients, Miall et al. (2018) showed that the loss of proprioception influenced the perception, control, and learning of aiming movements with the upper limb. The patients and control participants made aiming movements with a robotic manipulandum to targets that were perturbed on certain trials by an unexpected force. All participants were able to perceive, control, and learn the reaching movements, however, the neuropathy patients were slower to notice the perturbations when visual feedback was unavailable, and slower and more variable in their compensations to the perturbations. One of the most notable findings was the large individual differences between the three patients in terms of their learning of the reaching movements. It appeared that each had learned to rely on different sources of information and different cognitive strategies to compensate for their proprioceptive loss. 

**Tendon Vibration Technique**

A procedure in which movement is observed while proprioceptive feedback is distorted rather than removed involves the high-speed vibration of a tendon connected to a muscle that is an agonist in the movement of interest. This vibration distorts muscle spindle firing patterns, which leads to a distortion of proprioceptive feedback. Examples of the use of this technique can be found in several experiments reported by Verschueren. For example, one experiment (Verschueren, Swinnen, Cordo, & ­Dounskaia, 1999a) applied vibration to the tendons of the biceps and/or anterior deltoids of the preferred arm of blindfolded participants as they simultaneously drew circles with each arm. The results (see figure 6.5) 
showed that the vibration influenced the spatial characteristics of the circles drawn by the vibrated arm, but not for the nonvibrated, nonpreferred arm. In addition, the vibration of the preferred arm influenced the relative phase relationship between the two arms during the circle drawing.

An interesting aspect of tendon vibration is that it appears to have different effects on healthy people and people with some type of pathology, particularly those associated with proprioceptive deficits. For example, Wannaprom, Treleaven, Jull, and Uthaikhup (2018) showed that tendon vibration applied to the sub-occipital muscles of the cervical spine improved standing balance and walking speed in participants with neck pain but degraded performance in healthy controls. Researchers and clinicians have recently found that tendon vibration and whole-body vibration can improve motor performance in a range of patient populations.

**The Role of Proprioception in Motor Control**

The research examples we just considered show that people *can* carry out certain limb movements in the absence of proprioceptive feedback. Most notably, as demonstrated in the Spencer et al. (2005) experiment with the sensory neuropathy patients, the *timing synchrony between limbs* that characterizes the performance of bimanual coordination movements is not influenced by the lack of proprioception. However, there appear to be several distinct limitations to this capability. Because of these limitations, it is possible to identify the various roles of proprioceptive feedback in the control of human movement. We will consider three that are especially notable.

***Movement accuracy.***Several results from the experiments just discussed demonstrate that proprioception influences movement accuracy. In the Taub and Berman studies, the monkeys were clumsier while climbing, grasping, and grooming than they had been before deafferentation. In fact, they had difficulty grasping food with their hands in this condition. In the Bizzi experiments, the re­­searchers noted that when the animal’s posture was altered, pointing accuracy diminished in the deafferented condition. The Kelso, Holt, and Flatt experiment showed that human participants could maintain only spatial position accuracy following joint capsule replacement; distance movements were severely disrupted. And the experiments involving sensory neuropathy patients were consistent in demonstrating that the lack of proprioception resulted in large spatial errors. In addition, the experiment by Spencer and colleagues extended the evidence for movement accuracy problems without proprioception to include repetitive bimanual coordination movements.

The influence of proprioception on movement accuracy appears to be due to the specific kinematic and kinetic feedback provided by the proprioceptors to the CNS. Feedback about limb displacement provides the basis for spatial position corrections, which enable the limb to achieve spatial accuracy by a continuous updating of limb position to the CNS, which in turn can send movement commands that will modify the position accordingly, provided that the movement occurs for a sufficient amount of time to allow movement corrections to occur. In ­addition, pro‑prioceptors provide feedback about limb velocity and force, which influence movement distance accuracy.

***Onset of motor commands.***Proprioceptive feedback also influences the *timing of the onset of ­motor commands.* An experiment by Bard and ­colleagues (1992) provides a good example of evidence for this role. They compared movements of normal participants with a patient deafferented due to a sensory neuropathy. The participants were asked to simultaneously extend an index finger and raise the heel of the ipsilateral foot. When they performed this task in reaction to an auditory signal, both the normal and the deafferented participants performed similarly by initiating the finger extension first. We would expect this if a common central motor command were sent to each effector. Because of the difference in distance of ­efferent neural pathways to the finger and heel, 
finger movement would occur first. Conversely, when 
asked to do the task at their own pace, the normal participants raised the heel first; this suggests that they based timing of the finger movement onset on proprioceptive feedback about heel movement. In contrast, the deafferented patients performed as they had in the reactive situation, indicating that they used a central motor command rather than proprioceptive feedback as the basis for the timing of the ­onset of the heel and finger movements. The experiments by Miall et al. (2018) also suggest that the timing of the onset of motor commands is slower without proprioceptive feedback. The sensory neuropathy patients were slower to notice that their limbs had been perturbed during their aiming movements and slower and more variable in their compensations to the perturbations.

***Coordination control.***Finally, proprioception plays an important role in various aspects of the *co­or­dination of body and limb segments.* Two coordination characteristics influenced by proprioceptive feedback will serve to demonstrate this role.

First, *postural control* requires proprioceptive 
feedback. Although a considerable amount of rese­arch evidence shows that postural control is a function of many interacting variables, such as vision, the musculoskeletal system, and the vestibular system, activity of the cerebellum and basal ganglia, cognitive processes, the tactile sensory system, and proprioception, problems with any of these will lead to postural dysfunction. Jeka and colleagues have demonstrated (e.g., Jeka, Ribiero, Oie, & Lackner, 1998) the importance of proprioception in postural control by showing that proprioception, together with tactile information, functions to provide essential information to the CNS to enable a person to control upright stance posture in body sway situations. Additional evidence of the role of proprioception in postural control was provided by Barbieri 
et al. (2008) in an experiment in which they used the tendon vibration technique. The vibration of the Achilles tendon induced a three degree backward tilt of the participants’ vertical posture. An experiment by Doumas, Valkanidis, and Hatzitaki (2019) has also shown that standing postural sway increases markedly when healthy participants receive bilateral Achilles tendon vibration.

The second coordination characteristic involves the *spatial-temporal coupling between limbs and limb segments.* Results of the experiment by Messier 
et al. (2003), which we described earlier, showed that a sensory neuropathy patient demonstrated problems with coordinating the multijoint ­movements 
involved in reaching to a target in front of him. For between-limb movement coordination, the study by Verschueren et al. (1999a), which we considered earlier, showed the importance of proprioceptive feedback for the spatial and temporal coupling ­between the arms when we perform bimanual coordination tasks. And in another study by this same researcher and colleagues (Verschueren et al., 1999b), they demonstrated that proprioception influences the coupling between two limb segments of the same limb, such as the upper arm and forearm. Also, Spencer et al. (2005) demonstrated similar bimanual coordination problems for a sensory neuropathy patient, especially in terms of the control of spatial coordination and consistency between movements for a repetitive series of movements.

**VISION AND MOTOR CONTROL**

Our own personal experiences as well as research evidence tells us that of all our sensory systems, we tend to use and trust vision the most. For example, when you first learned to type or play the piano, you undoubtedly felt that if you could not see your fingers hit each key, you could not perform accurately. Beginning dancers and stroke patients learning to walk have a similar problem. They often act as if they cannot perform the activity if they cannot watch their feet.

These anecdotal experiences illustrate our tendency to give vision a predominant role when we perform motor skills. Research evidence also supports this phenomenon. The best example is a ­classic experiment by Lee and Aronson (1974) that is often referred to as the “moving room” experiment. Infants stood in a room in which the walls could move forward and backward. However, the floor was stationary and did not move. In this sensory conflict situation, the infants’ vision indicated they were moving, but their proprioceptors indicated they were not. The ­researchers observed the infants’ postural ­responses to the movement of the walls. When the walls moved, the children made posture correction adjustments that were in keeping with trying to maintain their standing balance as if the floor were moving. But because the floor did not move, their proprioceptors were not signaling that their bodies were losing stability. Only their visual systems detected any loss of balance. It is important to note that similar “moving room” effects on postural control have been reported more recently (see Barela, Barela, Rinaldi, & de Toledo, 2009; Chung & Stoffregen, 2011; Stoffregen, Hove, Schmit, & Bardy, 2006). 

The moving room experiments demonstrate the special priority we assign to vision in our daily ­activities. In those experiments, when the proprioceptors and vision provided conflicting information to the central nervous system, people gave attention to vision while ignoring the proprioceptors. The result was that they initiated unnecessary postural ­adjustments.

In the following sections we will discuss the role of vision in motor control in several ways. First, we will consider the neurophysiology of vision as it relates to motor control. We will then discuss some of the methods researchers use to investigate the role of vision in motor control. And finally we will look into several motor control issues that provide us with a general understanding of the many roles vision plays in the control of coordinated movement. 

It is important to note that this discussion is not intended to be a detailed description of the anatomy and physiology of the components of the visual system, but rather a general introduction to establish a basic understanding of the system. It is also important to point out that we will revisit the role of vision in the learning and control of motor skills in many other chapters of this book. For example, in chapter 7 vision is discussed in terms of its role in the control 
of specific skills; in chapter 8 it is considered in 
its role in the preparation of movement; and in chapter 9 vision is an important part of the discussion about attention, as it relates to the selection of environmental context information that is essential for action goal achievement. In addition, chapter 12 includes a discussion on vision as it relates to the stages of learning, and chapter 14 discusses the role of vision in the use of demonstration.

**The Neurophysiology of Vision**

Vision is the result of the sensory receptors of the eyes receiving and transmitting wavelengths of light to the visual cortex of the brain by way of sensory neurons known as the optic nerve. In a section about the eye in their neuroscience book, Bear, Connors, and Paradiso (2001) state, “the eye acts like a camera, forming crisp, clear images of the world. . . . Like a quality 35-mm camera, the eye automatically adjusts to differences in illumination and automatically focuses itself on objects of interest. The eye has some additional features not yet available on cameras, such as the ability to track moving objects (by eye movement) and the ability to keep its transparent surfaces clean (by tears and blinking)” (p. 281).

***Basic anatomy of the eye.***As illustrated in figure 6.6, 
the human eye is a fluid-filled ball with distinct components. The **cornea** is the most anterior component. It is a clear surface that allows light to enter the eye and serves as an important part of 
the eye’s optical system. Because it does not have blood vessels, it can be surgically removed with relative ease and, if necessary, a donated cornea can be transplanted. Behind the cornea are the pupil, iris, and lens. The **pupil** is the opening that lets light into the eye. Its diameter increases and decreases according to the amount of light detected by the eye. You have undoubtedly experienced this when you looked into a mirror and watched the pupil of your eye get larger and smaller depending on the amount of light in the room or shining in your eye. This diameter change is controlled by smooth muscle fibers within the iris. The **iris** ­surrounds the pupil and provides the eye its color. The **lens**, which sits just behind the iris, is a transparent structure that is responsible for allowing the eye to focus at various distances. The lens is held in place by the zonular fibers and its shape is controlled by the ciliary muscles shown in figure 6.6. The sclera, which makes up 80 percent of the eye, surrounds these structures. The anterior portion of this firm white capsule forms what we commonly call the “white” of the eye. The sclera functions to help maintain the shape of the eye and protect the eye’s inner structure. It also is an attachment site for the extrinsic eye muscles responsible for eye movement. The eye contains two chambers of fluid: *aqueous humor* is a clear fluid that fills the chamber between the cornea and lens, and *vitreous humor* is a viscous substance that fills the chamber between the lens and the back wall of the eye.

***The neural components of the eye and vision.***The neural aspects of vision begin with the **retina**, the structure that lines the back wall of the eye. Although it is part of the eye, the retina is actually an extension of the brain (Widmaier, Raff, & Strang, 2019). It contains various types of neurons and photoreceptor cells. The primary components of the retina include the *fovea centralis,* where objects seen in central vision are focused (hence the term *foveal vision*) and is therefore responsible for visual acuity, and the *optic disk,* where the axons of the retina’s neurons converge to transmit information to the optic nerve. The retina contains two types of photoreceptor cells called **rods** and **cones**, which play important roles in vision. Three roles are particularly relevant for the performance of motor skills. One role is that rods respond to low levels of light (which makes them responsible for night vision); cones respond only to bright light. Because of the specific levels of light to which they respond, these photoreceptors are the cause of the “temporary blindness” experience you have when the lighting in a room changes from very bright to dark. In such a situation the ­responsibility for light detection shifts from the cones to the rods, a process that requires a brief amount of time.

A second role for rods and cones relates to their location on the retina. Cones are concentrated at the center, which gives them a critical role in central vision and visual acuity. Rods are located more on the retina periphery and, therefore, are important for peripheral vision. Third, cones play a critical role in color vision.

The retina receives light waves from the cornea and lens, where the waves are *refracted*—that is, bent—in such a way that an observed image is turned upside down and reversed right to left on the retina. Image size and distance from the eye are determined by the size of the angle the light waves from the image form when they pass through the cornea; there is more bending for bigger and closer images to create larger images on the retina, and less bending for smaller and more distant images to create smaller images on the retina. This ­distinction is important for motor ­control in situations in which 
a person must make contact with or intercept a moving object, which we will discuss further later in this chapter and in chapter 7.

Axons of neurons in the retina called ganglion cells form the **optic nerve**, which is cranial nerve II and serves as the means of information transmission from the eye to the brain. As you can see in figure 6.7, the optic nerves from the two eyes meet near the base of the brain and form the **optic ­chiasm**, where the nerve fibers either continue to the same side of the brain or cross over to the opposite side of the brain and continue to the visual cortex at the back of the brain’s cortex. Whether optic nerve fibers cross at the optic chiasm or change to the ­opposite side of the brain depends on the visual field on the retina from which the fibers originate. The optic nerve fibers project to several brain structures, with the largest number passing through the lateral geniculate nucleus of the thalamus.

The **visual field** refers to the image or scene being viewed. As illustrated in figure 6.7, each eye sees a portion of the image or scene. One portion, referred to as the *nasal part of the visual field,* is detected by the inner halves of each eye, while the *temporal part of the visual field* is detected by the outer halves of each eye. The optic nerve fibers associated with the nasal part, which is projected through the lens and cornea to the interior side of the retinas, cross over at the optic chiasm to the opposite hemisphere of the cortex while the optic nerve fibers associated with the temporal part pass through the optic chiasm to remain in the same cortex hemisphere. The visual cortex of the brain unites these images in a way that allows us to see three dimensional images. As we will discuss later in this chapter, this *binocular vision*—that is, seeing with both eyes—is the basis for our depth perception as we observe the world around us.

**INVESTIGATING THE ROLE OF VISION IN MOTOR CONTROL**

Researchers use a variety of techniques to study the role of vision in motor control. The most direct technique involves the recording of eye movements as a person performs a skill. Other techniques provide indirect ways to determine how a person uses vision during the performance of a skill. We will briefly discuss these techniques in the following sections.

**Eye Movement Recording**

The recording of a person’s eye movements requires 
the use of specialized equipment that tracks the movement of the eyes and records where the eyes are “looking” at a particular time. A researcher can record the displacement of *foveal vision* for a specific time interval, as well as the place and the length of time the person fixates his or her gaze while tracking. One way researchers use this 
­technique is to have the participant observe a film simulation of a performance situation and then make a response. The movement of the eye is then plotted on the film scene to determine the spatial location of the participant’s eye movements (displacement), along with his or her gaze fixation characteristics related to observing the action. A more difficult way to use this procedure is to record eye movements while a person is actually performing a skill in the performance setting. (For a more detailed discussion about the use of eye-movement recordings, see Kredel, Vater, Klostermann, & Hossner, 2017 and Reimer & Sodhi, 2006.)

An experiment by Williams, Ward, Knowles, and Smeeton (2002) provides a good example of the use of eye movement recordings to investigate the use of vision in the performance of a ­motor skill. The experiment compared skilled and less-skilled tennis players as they viewed and ­responded to action sequences that would occur 
in a tennis match. The players observed videos of near-life-size images of opponents as a means of simulating play during a match. A player’s view was of an opponent positioned midcourt on the other side of the net. The videos presented opponents hitting forehand and backhand shots during match play situations toward the players’ left court, right court, center forecourt, and center backcourt. The players, who each wore an eye movement recording device, were asked to ­re­spond to each shot as they would in an actual tennis match, which is to respond as quickly and accurately as possible. The results showed that the skilled players spent more time viewing the opponent’s trunk-hip and head-shoulder areas than did the less-skilled players, while the less-skilled players spent more time than the skilled players viewing the opponent’s racquet.

**Temporal Occlusion Procedure**

This procedure is used to prevent an observer from seeing what is going to happen next in an action sequence by stopping a video recording the observer is watching or blocking vision by activating specialized goggles that are worn by the observer. The procedure allows an investigation of the *amount of time* a person requires to visually detect the environmental context information he or she uses to perform a skill. It is especially useful for skill performance situations in which choices among several movement alternatives must be made, which includes situations such as returning a serve in racquet sports, deciding whether to (and when to) dribble, pass, or shoot in basketball, or deciding when to walk across a busy street.

When film or video is used, the observer is required to make a response as quickly as possible when the recording is stopped at predetermined time points during the action sequence. An excellent and commonly cited example of the use of this procedure is in an experiment by Abernethy and Russell (1987), in which badminton players watched film sequences of a player making different shots. When the film stopped, participants marked their predictions of the landing positions of the shuttle. The film stopped at different times prior to, during, and after shuttle contact. By noting the relationship between the accuracy of a participant’s predicted shuttle landing location and the moment he or she made the decision, the researchers could determine when in the time course of the observed action the participant had visually selected the information needed to make a decision.

Some researchers have used the temporal occlusion procedure to determine when skilled athletes visually detect critical information in dynamic team ball games, such as soccer. In these types of games, successful performance is often dependent on the anticipation of an opponent’s or teammate’s action, such as whether he or she will pass the ball or make a shot at the goal. To assess when players detect this critical information, researchers have presented short video clips that stop at various amounts of time prior to the specific action; then they ask the player to indicate which type of action the player on the video will perform. The general conclusion from this type of research is that the critical information is detected in the final few seconds before the specific action (e.g., pass or shot at goal) (see North & Williams, 2008).

The other temporal occlusion procedure involves the use of specially prepared visual occlusion spectacles, such as those seen in figure 6.8. The lenses contain liquid crystals that the experimenter can activate or deactivate to cause the lenses to be transparent or occluded. The change in the state of the lenses occurs very quickly (1–5 msec). A benefit of the lenses is that they change the visual condition almost instantaneously without the eyes requiring the typical amount of time to adapt to changes ­between light and dark conditions. The visual ­occlusion lenses provide an advantage over the procedure of stopping a video or film by allowing researchers to have research participants perform skills in their typical environmental context. One limitation with this technique is that researchers have typically triggered the visual occlusion spectacles using a manual button press. This limitation has recently been overcome with the development of a laser curtain that is triggered automatically when a performer’s movement distorts the lasers (Brenton, MŸller, Rhodes, & Finch, 2018). With this set up, researchers now can more precisely occlude vision at specific time points within an opponent’s action.

A question that arises from the use of the temporal occlusion technique in laboratory environments is this: Are the results obtained from this procedure consistent with the way people use vision when performing the same skills in real-world environments? Two experiments by Farrow, Abernethy, and ­Jackson (2005) addressed this question using novice and skilled tennis players. Results indicated that the ­laboratory-based temporal occlusion technique generalizes very well to real-world environments.

**Event Occlusion Procedure**

This procedure, also referred to as the *spatial occlusion procedure,* involves editing film or video recordings to occlude parts of the environmental context or the performer. The *event occlusion procedure* is used to identify the specific visual information a person uses to make a response. Parts of each frame of film or video are masked so that the observer cannot see selected parts of the action. Figure 6.9 presents an example of this procedure, taken from the second part of the Abernethy and Russell (1987) study. In their experiment, participants predicted the landing location of the shuttle when they could not see the arm and racquet, racquet, head, or legs of the person hitting the shuttle. The logic of this approach is that if the person performs worse without being able to see a specific feature of the opponent’s action, then that feature includes the ­visual information the ­person uses to determine the location of the shot.

**THE ROLE OF VISION 
IN MOTOR CONTROL**

Vision plays many roles in the control of coordinated movement. We will consider some of these roles in the following sections by discussing them in the context of several issues that researchers have investigated. We will further explore the role of vision in motor control in chapter 7 by ­discussing its involvement in the control of specific motor skills, such as prehension, locomotion, and catching and striking objects.

**Monocular versus Binocular Vision**

One of the questions researchers have investigated concerning the role of vision in motor control relates to *the use of monocular (i.e., one eye) ­compared to 
binocular (i.e., two eyes) vision* to perform motor skills. Research evidence (e.g., Coull et al., 2000; Goodale & ­Servos, 1996; Servos, 2000; Zago, McIntyre, Senot, & Lacquanti, 2009) has shown that the motor control system operates more effectively and efficiently when it receives visual information from *both* eyes. Although people can reach and pick up objects when the use of only one eye is available, the accuracy and efficiency of the movement decrease as the distance to the object increases. Experiments (e.g., Coull 
et al., 2000; Grant, 2015) that have shown this influence of distance provide ­support for the view that binocular vision is important for *depth perception.*

Monocular vision appears to interfere with movement planning and movement execution. 
When only one eye is available during movement planning, people consistently underestimate the distance to objects and the size of the objects. These underestimates are not corrected during the movement itself, which also indicates the need for binocular vision to provide important information for correcting errors in limb movement. Research investigations of these problems have shown errors in movement kinematics during the movement (e.g., Bingham, 2005; Jackson, Newport, & Shaw, 2002) and movement end-point accuracy (e.g., Chapman, Scally, & Buckley, 
2012; Heath, Neely, & Krigolson, 2008). Interestingly, when people are not permitted to use binocular ­vision and must reach for and grasp an object using monocular vision, they will move their heads in a manner that enables them to obtain more accurate information about the size of an object and the distance to it (see Marotta, Kruyer, & Goodale, 1998). Reaching with monocular vision can be improved when proprioceptive information is concurrently available to help localize a target in space. For example, participants performed a bead threading task onto a vertical needle faster and more accurately when they grasped the needle with their other hand than when the needle was freestanding (Tugac, Gonzalez, Noguchi, & Niechwiej-Szwedo, 2019). 

Binocular vision also provides better movement control than monocular vision for other motor skills, such as locomotion and intercepting moving objects. For example, research evidence shows that when a person is walking along a pathway and must step over an obstacle, binocular vision is important for the detection of the three dimensional ­characteristics of the environment needed to initiate and step over the obstacle (Patla, Niechwiej, Racco, & Goodale, 2002). This information enables the person to move the stepping leg accurately to clear the obstacle while stepping over it. Here again we see evidence for the importance of binocular vision for visual depth perception.

Finally, binocular vision also provides important information to help us intercept moving objects. 
An example of research evidence supporting this role for binocular vision was reported in an experiment in which participants used monocular or binocular vision to hit a moving object (Scott, van der Kamp, Savelsbergh, Oudejans, & Davids, 2004). Results showed that the participants using monocular ­vision missed the object more frequently, indicating that binocular vision provides important information to guide interceptive actions in skills such as hitting a moving ball.

**Central and Peripheral Vision**

Another question of interest relates to the *roles of central and peripheral vision* in the control of movement*.* **Central vision**, which is sometimes called *foveal* vision, detects information only in the middle 2 to 5 degrees of the visual field. **Peripheral vision**, on the other hand, detects information in the visual field outside these limits. For most people, the visual field extends approximately 200 degrees horizontally and 160 degrees vertically. The current understanding is that each makes specific contributions. To demonstrate how central and peripheral vision each provide distinct information for motor control, we will consider research related to two types of motor skills related to everyday living: reaching and grasping an object, and locomotion. 

First, imagine yourself sitting at a table with the intent to pick up a cup sitting on the table. In this situation, as you prepare to move, central vision fixates on the cup to obtain information on its size, shape, and distance from your present position. As you begin to reach for the cup your moving hand is seen by peripheral vision, which will provide online feedback to guide the reaching and grasping of the cup. As your hand nears the cup, central vision becomes critical again for providing information needed to actually grasp the cup.

There is an abundance of research evidence to support the roles of central and peripheral vision in the prehension task situation just described. For example, an experiment by Sivak and MacKenzie (1990) showed that when participants could use only central vision to reach and grasp an object, the organization and control of the movement to the object was affected, but not the grasping of the 
object. When the researchers blocked the partici‑
pants’ use of central vision, which meant they could use only peripheral vision for reaching and grasping an object, problems occurred with both the transport and grasp phases. 

The results of the Sivak and MacKenzie experiment match those reported in other research by showing the distinct roles played by central and peripheral vision in the control of limb movements, especially those involved in manual aiming and prehension (see Gaveau et al., 2014 and Jeannerod & Marteniuk, 1992, for reviews of this research). 

Central and peripheral vision also play different roles in locomotion. For example, research has shown that when we walk along a pathway, central vision provides information that guides us so that we can stay on the pathway, whereas peripheral vision is important to provide and update our knowledge about the spatial features of the walking environment, such as pathway dropoffs or bumps (Turano, Yu, Hao, & Hicks, 2005). The information received through ­peripheral vision during locomotion is particularly important to help people maintain their action goal without being affected by pathway problems, such as obstacles, other people, or irregular steps on a stairway.** 

In a study that combined prehension and locomotion, Graci (2011) had participants pick up a full glass of water on a table located at the end of their walking path and move the glass to a new location on the table. They performed this task with either full vision of their lower body, the table and glass, and with occluded vision, which prevented them from using peripheral vision to see the table and their lower body when they reached the table. They could always see the glass of water. One of the effects of not having peripheral vision available was the time to contact the glass, which was calculated from the end of their last step until their hand reached the glass, Without the availability of peripheral vision, they increased their time to contact the glass by approximately 40 percent.

One of the most important sources of information available to peripheral vision for controlling actions is **optical flow**. Optical flow refers to the moving pattern of rays of light that strikes the retina of the eye from all parts of the environment. The word “flow” is significant because it indicates the dynamic nature of this visually detected information. When our head moves through the environment, whether through head turning, postural sway, or locomotion, our visual system detects and uses patterns of optical flow that covary precisely with the speed and direction of our head motion. Similarly, movement of an object, a person, or a surface provides the visual system with a different pattern of optical flow that specifies the direction and speed with which that particular feature of the environment is moving. Differentiating the various patterns of optical flow allows us to effectively control posture, locomotion, and object manipulation and to coordinate our actions with the regulatory conditions in the environment. (For an excellent review of research concerning optical flow and an ­experiment involving the use of optical flow, see ­Konczak, 1994, and for a review of the development of responsiveness to optical flow, see ­Anderson, Campos, & Barbu-Roth, 2004.)

***Two visual systems for motor control.***The distinctive behavioral roles for central and peripheral ­vision, along with supporting neurophysiological evidence, have led some researchers to propose that the visual system is actually two anatomical systems that operate in parallel (see Brown, ­Halpert, & Goodale, 2005, for a more detailed discussion of the two vision systems). Paillard (1980), for example, proposed that a *kinetic* visual channel was respon­sible for processing visual information in peripheral ­vision. This channel would process high-speed movement information and control limb movement direction. To process visual information in central vision and for slow-speed movements, Paillard proposed a *static* visual channel.2For a review of research that has tested Paillard’s two visual systems model, and two experiments that support and extend this model, see Proteau, Bolvin, Linossier, and Abahnini (2000). And, for a defense of the model, see Milner, Ganel, and Goodale (2012). 2 Other researchers have proposed similar two-­channel visual systems but have given them different names. Some examples include the *focal* vision system, which is responsible for the detection of static objects by central vision, and the *ambient* vision system, which detects objects and movement around us, involving peripheral vision (Trevarthen, 1968); another is the *vision-for-perception* system, which would be responsible for recognizing and describing what a person is seeing, and the *vision-for-action* system which would be responsible for perceptually guided movements ­(Brown, Halpert, & Goodale, 2005; Goodale & ­Milner, 1992).

When described in anatomical terms, the two visual systems identified by Goodale and Milner (1992) have been referred to as the *ventral stream,* which is used for fine analysis of the visual scene into form, color, and features—in other words, what a person is seeing—and the *dorsal stream,* which is responsible for the spatial characteristics of what is seen as well as for guiding movement 
(e.g., Cameron, Franks, Enns, & Chua, 2007; Reed, Klatzky, & Halgren, 2005). As this designation of the two systems suggests, the neural pathways of the two systems are anatomically distinct. To use the Goodale and Milner terms for the two systems, the vision-for-perception system processes visual information via a cortical pathway leading from the primary visual cortex to the temporal lobe, whereas the vision-for-action system routes information from the primary visual cortex to the posterior parietal cortex (Brown, Halpert, & Goodale, 2005; Reed et al., 2005).

One important characteristic of the two systems relates to our conscious awareness of the information detected by each system. We are generally ­consciously aware of information detected by the ventral stream, but not of that detected by the dorsal stream. This disassociation leads to some interesting behaviors in patients with damage to the ventral or dorsal stream. For example, a patient with damage to the ventral stream could have no conscious perception of the size or orientation of an object, but could pick up and manipulate the object without any problems (Goodale & Milner, 1992).

**Perception-Action Coupling: 
The Coordination of Vision and Movement**

When you play a video game on your computer and you must move the mouse or joystick quickly and precisely so that the object you control on the screen hits a target, or when you want to quickly unlock the door to your residence, your eyes and hand work together in a coordinated way to allow you to carry out these actions. Similarly, when you want to kick a moving ball or stop it with your foot, your eyes and feet coordinate so that you can successfully carry out the intended action. The spatial and temporal coordination of ­vision and the hands or feet in these types of skill performance situations is an example of what is known as perception-­action coupling. This means that the visual perception of the object and the limb movement required to achieve the action goal are “coupled,” or coordinated, in a way that enables people to perform eye-hand and eye-foot coordination skills. Perception-action coupling is not confined to the hands and feet or to the visual system, but can be seen in any situation where an action, such as posture or locomotion, is coordinated with features of the environment.

One of the ways researchers have determined this coordination characteristic is by pairing the eye movement recording technique, which we discussed in the preceding section, with the motion analysis technique discussed in chapter 2. Although ­perception-action coupling can involve any movement (an excellent example is the visual-postural coupling described earlier in Lee & Aronson’s [1974] moving room experiment), we will focus here on the coupling of vision and hand movements.

For eye movement analysis, the characteristic of interest is the *point of gaze,* which is the specific location in the environment on which central 
(i.e., foveal) vision is fixated at any particular moment. For example, to assess the coordination of vision and hand movement to a target, researchers calculate the relationship between the timing and/or location of the termination of the point of gaze with the timing and/or location of the hand movement. If the point of gaze and hand movement are temporally or spatially coupled, the point of gaze should be at a specific location at a consistent proportion of the total movement time and/or distance of the hand movement.

A good example of research evidence that demonstrates the coupling between vision and hand movement is an experiment by Helsen, Elliott, Starkes, and Ricker (1998). Participants moved their index fingers 40 cm to the right from a starting location in front of them to a 1 cm by 2 cm target as fast as 
­possible. Both point of gaze and hand movements tended to undershoot the target and then made one or more corrections to hit the target. The analysis of eye and finger movements showed that the participants typically initiated eye movements approximately 70 msec *before* they began to move their hands from the start location. The initial eye movement moved the point of gaze very close to the target (about 95 percent of the total distance), after which participants made a second eye movement to correct the undershooting of the first. The point of gaze typically arrived at the target 450 msec *before* the finger, which would allow for inflight hand movement corrections based on visual feedback. The researchers found evidence for *temporal coupling* between the eye movements and hand movements because the completion of the initial eye movement coincided with the timing of the peak acceleration of the hand movement. Evidence for *spatial coupling* was shown by the point of gaze consistently terminating on the target when the hand movement was at 50 percent of the total movement distance.

Since that experiment, the same researchers (Helsen, Elliott, Starkes, & Ricker, 2000) showed that the initiation of elbow and shoulder movements is also coupled in time with eye and finger movement initiation. The sequence of events was that the eyes moved first, followed by the shoulder, then the elbow, and finally the finger. On every trial for every participant, the point of gaze was on the target long before the hand arrived at the target. Similar coupling effects have been demonstrated for vision and feet during locomotion. For example, researchers have shown that people with vision gaze ­control deficits exhibit foot lift and stepping problems during stair climbing (DiFabio, Zampieri, & Tuite, 2008). Thus, the results of these experiments and others like them support the importance of vision for picking up critical spatial information to initiate and guide limb movements to a target and to provide spatial and temporal feedback to ensure the accurate arrival of the limb at the target.

**The Amount of Time Needed to Make 
Vision-Based Movement Corrections**

An important factor that influences the role of vision in motor control is the amount of time available to use visual feedback to make movement corrections while the movement is in progress. Recall from our discussion in chapter 5 of the closed-loop motor control system that feedback can be used to make movement corrections only when the person has sufficient time to detect a movement error and modify the movement. This means there is a minimum total movement time requirement in order for the performer to be able to use visual feedback to correct movement errors prior to the completion of the movement.

The important question here is: *What is the minimum amount of time required* *for movement corrections* to be carried out on the basis of visual feedback? Researchers have been attempting to answer this question for more than 100 years, beginning with research by Woodworth in 1899. The most vigorous effort to investigate this question ­occurred in the latter part of the twentieth century, beginning with an influential experiment by Keele and Posner 
in 1968. Unfortunately, all this research effort has not provided us with a precise answer to the question (see Carlton, 1992 and ­Elliott, Helsen, & Chua, 2001, for excellent reviews of this research). Part of the problem is that different experimental procedures have resulted in a variety of time estimates for the processing of visual feedback.

The most common experimental procedure has been to have people perform manual aiming movements with different goal movement times. On some trials, the lights would go out just as the person ­began to move, whereas on other trials the lights ­remained on. The logic to this procedure was that if visual feedback were necessary, aiming accuracy would decrease with the lights out because the person could not see the target and therefore would not be able to use visual feedback. When participants did not know when the lights would be on or off, the amount of time to process visual feedback was estimated to be between 190 and 260 msec. However, later experiments used the same lights-­on-or-off technique, but participants knew when they would perform under each condition (e.g., Elliott & Allard, 1985; Zelaznik, Hawkins, & ­Kisselburgh, 1983). This advance knowledge indicated that visual feedback could be used in less than 100 msec.

Other experimental procedures have led re­search­ers to conclude that visual feedback can be processed in amounts of time that are faster or slower than those estimated by the lights-on-or-off procedure. 
These have included such procedures as distorting the visual information by having people wear prism glasses (e.g., Smith & Bowen, 1980, ­estimated the time to be about 150 msec); moving the target location after the person initiated a movement to a target (e.g., Brenner & Smeets, 1997, 2009, ­estimated the time to be between 110 and 150 msec); and preventing visual feedback for portions of the distance to the target (e.g., Spijkers & Lochner, 1994, estimated the time to be about 135 msec).

Although it is not possible to establish an exact minimum amount of time required to use visual feedback to enable movement corrections, it ­ap­pears that an estimate of a range from *100 to 160 msec* is reasonable to capture movement correction limits for most motor skills. However, it is important to note that the minimum amount of time could be faster in situations where the person is anticipating the need to make a movement correction.

***Application to real-world motor skill perfor­mance.***
How does the question concerning the minimum amount of time needed to make a movement correction relate to the performance of motor skills in real-world situations? Knowing this time limi­­­­tation for human performance becomes especially 
relevant when we try to evaluate performance associated with sports skills and activities of daily living. For example, whether or not a person will have time to adjust his or her initial hand movement to catch a ball will depend on the amount of time available to catch the ball. If the ball speed is too fast or the distance the ball travels is too short to allow any movement modification, success at catching the ball will depend on the initial hand position. Similarly, if a person is stair climbing at a pace that is too fast to allow foot-position adjustments while the foot is in flight, the risk of falling increases.

**Time to Contact: The Optical Variable** *Tau*** 

In situations in which a person moves toward an object to make contact with it, or the object moves toward the person, such as when a person is catching or hitting a thrown ball, vision plays an important role in specifying *when* to initiate the action and make contact with the object. The important visual information in these situations is the *time to contact,* which is the amount of time remaining until the object contacts the person (or vice versa) from a specific distance (see Bootsma & Peper, 1992). *Time to contact is specified according to the relative rate of change of the size of the image of the object on the retina of the eye.* As the person approaches the object, or vice versa, the object produces an increasingly larger retinal image at an increasingly larger rate of expansion. When this image attains a certain critical rate of expansion, it triggers the action required by the situation.

In the early 1970s, David Lee (1974) provided evidence that time to contact is specified by an ­optical variable, which he termed *tau* (τ). He also showed that *tau* can be quantified mathematically by relating object size, the distance of the object from the person, and the angle subtended at the person by the object size and distance. In mathematical terms, *tau* is the inverse of the relative rate of change of the visual angle subtended by the moving object, given the speed of approach of the object is constant. Since the publication of Lee’s article, numerous motor control and learning researchers have investigated the role *tau* plays in controlling our actions and movements (see Lee, 2009 and Lee 
et al., 2009 for summaries of this research). 

The motor control beneÞt of the *tau* variable is its predictive function, which allows action ­initiation and object contact to occur “automatically” at a speciÞc time to contact regardless of the speed of the object or person. When driving a car, for example, the driver’s initiation and amount of braking ­action to avoid collision with another car is not dependent on the driver’s cognitive knowledge of the distance to and velocity of the other car. Rather, by specifying the time to contact at any distance and velocity, the rate of change of the size of the retinal image of the other car provides the information needed by the driver to ­determine 
the type of braking, or deceleration, required by the situation. We will consider *tau* and its relation to specific ­motor skills in chapter 7.

**SUMMARY**

Touch, proprioception, and vision are important sources of feedback involved in movement control.

Touch provides the tactile sensory information that is important for the control of movement. Mechanoreceptors in the skin are the sensory receptors that provide this information by detecting skin stretch and joint movement. Research has shown that tactile feedback is important in motor control for influencing movement-related characteristics such as movement accuracy, movement consistency, force adjustments for ongoing movements, and for assisting ­proprioception in the estimation of movement distance.

Proprioception information is detected by pro‑
prioceptors located in the muscles, tendons, ligaments, and joint capsules. The muscle spindles are the most important receptors for providing the CNS with feedback about limb position, ­direction, and velocity. The Golgi-tendon organs detect changes in muscle force. The joint receptors provide feedback about joint movement when the angular movement or joint positions are at their extreme limits.

To investigate the role of proprioception in 
motor control, researchers use several experimental techniques that remove or distort pro‑
prioceptive feedback. The results of this research have established that proprioceptive feedback ­influences several motor control functions, including movement accuracy, the timing of 
the onset of motor commands, and various aspects of the coordination of body and limb segments, such as postural control, the spatial-temporal coupling between limbs and limb segments, and adaptation to movement situations that require the use of nonpreferred coordination patterns.

We tend to use and trust vision more than our other senses for information to control movement. Vision’s dominant role as a source of sensory information is commonly observed in situations in which vision and proprioception provide conflicting information about characteristics of our movement, a phenomenon that was demonstrated in the “moving room experiment.”

Vision results from sensory receptors in the eyes that receive wavelengths of light through structures such as the cornea, pupil, lens, and retina and transmit the information that reaches the retina to the visual cortex in the brain by way of the optic nerve.

To investigate the role of vision in motor control, researchers use several experimental techniques, such as eye movement recording and the occlusion of temporal and event (spatial) information in a scene.

Research evidence has established that vision plays several important roles in motor control, such as providing depth perception for interacting with objects, other people, and our daily environment; providing information that enables us to identify objects, people, and other environmental context components; providing information that enables us to move through our environment; ­coordinating movements involved in eye-hand coordination activities; and making movement corrections as we move.

Research evidence shows that the visual system is actually two anatomical and physiological systems. The vision-for-perception system allows us to recognize and describe what we see; the ­vision-for-action system allows us to move in our environment.

In situations in which a person moves toward an object to make contact with it, or in which an ­object moves toward a person, the visual variable *tau* specifies the amount of time until contact. At a critical time to contact, the motor control system initiates the action required in the situation.

**POINTS FOR THE PRACTITIONER**

Because touch, proprioception, and vision are important for enabling people to carry out their daily living and recreational activities, it is important to determine how deficits in any of these sensory systems may explain difficulties a person may have performing a specific activity. Movement accuracy and coordination problems may be the result of sensory-related problems.

People will typically use vision to substitute for touch and/or proprioception when they begin learning a skill that requires them to rely on touch and/or proprioception for successful perfor­mance, such as watching their fingers hit keyboard keys when learning to keyboard or play the piano, watching their hands when learning to dribble a ball, or watching their feet when learning a dance routine.

Make certain that a person’s central vision (i.e., the point of gaze) is focused directly on an object that needs to be grasped or caught to ensure the successful achievement of the action goal.

People can make movement corrections while performing a skill only when there is a sufficient amount of time to make the corrections. As a result, movement errors may be the result of movement or environmental context conditions that were too fast to allow a correction, even though the person knew he or she needed to make a movement adjustment. Examples include ball speed that is too fast to allow a correction of hand position to catch it or of bat or racquet position to hit it or a person moving too fast to correct a foot position or movement error when stepping over an obstacle in the pathway or on a stair step when ascending stairs.

**RELATED READINGS**

Berencsi, A., Ishihara, M., & Imanaka, K. (2005). The functional role of central and peripheral vision in the control of posture. *Human Movement Science, 24,* 689–709.

Croix, G., Lejeune, L., Anderson, D. I., & Thouvarecq, R. (2010). Light fingertip contact on thigh facilitates handstand balance in gymnasts. *Psychology of Sport and Exercise, 11,* 330–333.

Ergen, E., & Ulkar, B. (2008). Proprioception and ankle injuries in soccer. *Clinics in Sports Medicine, 27,* 195–217.

Fajen, B. R., Riley, M. A., & Turvey, M. T. (2009). ­Information, affordances, and the control of action in sport. *International Journal of Sport Psychology, 40,* 79–107.

Glasauer, S., Schneider, E., Jahn, K., Strupp, M., & Brandt, T. 
(2005). How the eyes move the body. *Neurology, 65,* 1291–1293.

Gnanaseelan, R., Gonzalez, D. A., & Niechwiej-Szwedo, E. (2014). Binocular advantage for prehension movements performed in visually enriched environments requiring visual search. *Frontiers in Human Neuroscience, 8(959):* doi: 10.3389/fnhum.2014.00959.

Gobel, D. J., Coxon, J. P., Van Impe, A., Geurts, M., Van Hecke, W., Sunaert, S., . . . Swinnen, S. P. (2012). The neural basis of central proprioceptive processing in older versus younger adults: An important sensory role for right putamen. *Human Brain Mapping, 33*(4), 895–908.

Hajnal, A., Fonseca, S., Harrison, S., Kinsella-Shaw, J., & Carello, C. (2007). Comparison of dynamic (effortful) touch by hand and foot. *Journal of Motor Behavior, 39,* 82–88.

Hecht, D., & Reiner, M. (2009). Sensory dominance in combinations of audio, visual and haptic stimuli. *Experimental Brain Research, 193,* 307–314.

Heinen, T., & Vinken, P.M. (2011). Monocular and binocular vision in the performance of a complex skill. *Journal of Sports Science and Medicine, 10*(3), 520–527.

Kanade, R. V., Van Deursen, R. W. M., Harding, K. G., & Price, P. E. (2008). Investigation of standing balance in patients with diabetic neuropathy at different stages of foot complications. *Clinical Biomechanics, 23,* 1183–1191.

Khan, M. A., Lawrence, G. P., Franks, I. M., & Buckolz, E. (2004). The utilization of visual feedback from peripheral and central vision in the control of direction. *Experimental Brain Research, 158,* 241–251.

Klinger, C. M., Brodoehl, S., Witte, O. W., Guntinas-Lichius, O., & Volk, G. F. (2019). The impact of motor impairment on the processing of sensory information. *Behavioural Brain Research, 359,* 701–708.

Mayo, A. M., Wade, M. G., & Stoffregen, T. A. (2010). ­Postural effects of the horizon on land and at sea. *Psychological ­Science, 20*(10), 1–7.

Milner, A. D. (2017). How do the two visual streams interact with each other? *Experimental Brain Research*, *235*, 1297–1308.

Poliakoff, E. (2010). Introduction to special issue on body representation: Feeling, seeing, moving and observing. *Experimental Brain Research, 204,* 289–293.

Proffitt, D. R. (2006). Distance perception. *Current Directions in Psychological Science, 15,* 131–135.

Starkes, J., Helsen, W., & Elliot, D. (2002). A mŽnage a trois: The eye, the hand and on-line processing. *Journal of Sports Sciences, 20,* 217–224.

Weiler, H. T., Pap, G., & Awiszus, F. (2000). The role of joint ­afferents in sensory processing in osteoarthritic knees. ­*Rheumatology, 39,* 850–856.

Yousif, N., Cole, J., Rothwell, J., & Diedrichsen, J. (2015). Proprioception in motor learning: Lessons from a deafferented subject. *Experimental Brain Research, 233*, 2449–2459.

**STUDY QUESTIONS**

Describe the sensory receptors located in the skin that provide tactile sensory information related to movement.


Discuss three movement-related characteristics influenced by tactile sensory information; indicate how we know each of them is influenced by tactile sensory information.


Describe three types of proprioceptors, where each is located, and the type of movement information each provides.


Discuss three methods researchers have used to investigate the role of proprioception in motor control and what the results of that research have told us about two roles of proprioception in the control of movement.


Describe the anatomical pathway the image of an object would take through the eye and visual neural system.


Discuss why binocular vision is superior to monocular vision for perceiving distance to objects and the size and shapes of objects.

(a) Discuss the different roles of central and ­peripheral vision in the control of movement, and explain how these roles indicate that there are two anatomical visual systems. (b) If you wanted to reach for a cup of water to take a drink from it, describe how the two visual systems would operate to allow you to do this task.

Describe the spatial and temporal relationships between your eyes and hand when you move the computer mouse so that the cursor points to an icon on the monitor.


Discuss in terms of vision’s involvement in the control of movement corrections, why a volleyball player who jumps up at the net to block a spike is vulnerable to the offensive player successfully dinking the ball over his or her hands.

**Application Problem to Solve** When you reach for and grasp a glass of water, how do you know how far to reach, how much force to use to grasp the glass, and how to keep the glass from slipping out of your hand as you bring it to your mouth to drink from it? When you walk across campus, how do you not trip over a curb when you cross a street or bump into someone who is walking in front of you or in the opposite direction toward you?

**FIGURE 6.1** Skin receptors involved in tactile sensation. (Note that the figure is not drawn to scale; for example, Pacinian corpuscles are actually four to five times larger than Meissner’s corpuscles.) *Source:* From Widmaier, E. P., 
Raff, H., & Strang, K.T. (2019). *Vander’s human physiology: The mechanisms of body function* (15th ed.). New York, NY: McGraw-Hill.

**A CLOSER LOOK**

**Typing without Tactile Sensory Feedback**

In an experiment designed to investigate the importance of tactile sensory feedback for the control of movement, Rabin and Gordon (2004) had twelve skilled typists (all could type more than 50 words per minute) type on a personal computer keyboard lists of sentences that were placed in front of them. They could see the computer monitor but not their hands as they typed. They were instructed not to correct errors. The typists typed the sentences before and during anesthesia of the right index finger. The sentences were short and consisted of letters typed by the left hand except for one letter (*y*, *u*, *h*, *n*, *m*), which is typed by the right index finger (e.g., “we was*h*ed”). Also included in the sentences were words that required the right index finger to type all the letters (e.g., *yummy*).

***The anesthesia:***A mixture of long-acting 2 percent lidocaine and short-acting 2 percent marcaine was ­injected near the median nerve on either side of the distal interphalangeal joint of the right index finger.

**Results**

***Typing accuracy:***Without the right index finger anesthetized, the typists made 3.5 percent of the keypress errors with their right index finger. But, with the right finger anesthetized, the percentage increased to 16.5 percent. Almost all of these errors (90 percent) were “aim” errors, that is, missing the key. No other ­fingers on either hand showed an increase in errors with the right finger anesthetized.

***Finger kinematics:***With anesthesia, finger trajectories from a preceding key to the target key were ­similar to what they were before anesthesia, al­though there was greater trial-to-trial variability with ­anesthesia.

1*Kinesthesis* is a term that is related to the term *proprioception*. There has been considerable debate about the distinction between them. Sometimes they are used to refer to specific types of sensory information; in other cases they are used synonymously. For the purposes of this book, the term *proprioception* is used to refer to sensory information about body and limb position and movement as well as the force and effort associated with muscle contraction that is transmitted to the CNS from the pro­prioceptors.

**FIGURE 6.2** A muscle spindle and Golgi-tendon organ. (Note that the figure is not drawn to scale; for illustration ­purposes, the muscle spindle is exaggerated in size compared to the extrafusal muscle fibers.) *Source:* From Widmaier, E. P., Raff, H., & Strang, K. T. (2019). *Vander’s human physiology: The mechanisms of body function* (15th ed.). New York, NY: McGraw-Hill. Adapted from Elias, H., Pauly, J. E., & Burns, E. R. (1978). *Histology and human microanatomy* (4th ed.). New York, NY: Wiley.

**proprioception** the perception of limb, body, and head movement characteristics and the force and effort associated with muscle contraction; afferent neural pathways send to the central nervous system proprioceptive information about characteristics such as limb movement direction, location in space, velocity, and muscle force. **proprioceptors** sensory neurons located in the muscles, tendons, ligaments, and joints. These ­neurons pick up information about body and limb position and changes in position. **muscle spindles** a type of proprioceptor consisting of specialized muscle fibers that lie within the fibers of most skeletal muscles; they detect changes in muscle length. **Golgi-tendon organs (GTOs)** a type of proprioceptor located in the skeletal muscle near the insertion of the tendons into the muscle; they detect changes in muscle tension, or force. 


**FIGURE 6.3** A simplified diagram of the knee jerk reflex. Note that the neural branch that inhibits antagonist muscles and the branch that activates synergistic muscles are not shown.

**joint receptors** a collection of various types of proprioceptors located in the joint capsule and ligaments; they detect changes in joint movement at the extreme limits of movement and position. **deafferentation** a procedure that researchers use to make proprioceptive feedback unavailable (through surgically severing or removing afferent neural pathways involved in the movement); it also can result from injury, surgery, or disease to afferent neural pathways involved in proprioception. 


**FIGURE 6.4** Results of the experiment by Blouin et al. showing the amount of error during the reproduction of an arm position for normal and deafferented subjects with vision of the environment available (structured) or not available (unstructured), and vision of the moving arm available or not. *Source:* Data from 
Blouin, J. et al. (1993). Reference systems for coding spatial information in normal 
subjects and a deafferented patient. *Experimental Brain Research*, *93*, 324–331, 
New York, NY: Springer-Verlag.

**FIGURE 6.5** Results from the experiment by Verschueren et al. showing the effects of vibrating the tendons attached to the biceps and anterior deltoid of the preferred arm during bimanual circle drawing with no vision of the arms. The top row shows one participant’s drawings during one trial when no tendon vibration was applied. The bottom row shows the drawings by the same participant during one trial with tendon vibration. *Source:* Adapted from Figure 1A–D, p. 185, of Verschueren, Swinnen, Cordo, & Dounskaia (1999). *Experimental Brain Research, 127,* 182–192, 1999 New York, NY: Springer-Verlag.

**A CLOSER LOOK**

**Vision and Proprioception in Gymnastics**

Researchers have investigated the role of proprioception for the performance of gymnastics skills by blocking or distorting vision while the gymnast performs. Although this method is an indirect method, since all other sensory systems except vision function normally, the movement accuracy results of experiments that have used this technique correspond with those described in this chapter in which proprioception was directly blocked or distorted. The following three experiments are some examples of the use of distorting or blocking the vision of gymnasts while they performed skills commonly used in gymnastics events.

Robertson and Elliott (1996) distorted the vision of skilled gymnasts as they walked on a balance beam. The results showed that the gymnasts increased the number of steps they used to walk as fast as possible along the beam and increased their movement form errors.

Danion, Boyadijan, and Marin (2000) blocked the vision of skilled gymnasts by blindfolding them as they attempted to walk a straight line for 15 m 
on an open floor. The results showed that the gymnasts veered from the straight line as they walked.

Gautier, Thouvarecq, and Chollet (2007) compared handstand performances by skilled gymnasts with their eyes open and closed. Results showed that with their eyes closed, their vertical posture showed more anterior–posterior lean than they had with their eyes open.

***Conclusion:***The results of these three experiments, which are representative of other gymnastics specific studies, demonstrate that although gymnasts have learned to rely on proprioception as a source of feedback to help control movement, they use proprioception in combination with vision. When vision is not available in situations in which it normally is available, specific movement characteristics are negatively affected.

**A CLOSER LOOK**

**The “Rubber Hand Illusion”: An Example of Vision Overriding 
Proprioception and Tactile Senses**

A neuroimaging study reported in *Science* by Ehrsson (2004) and his colleagues in England provided evidence of the brain activity that underlies a perceptual illusion known as the “rubber hand illusion,” which was first ­described by Botvinick and Cohen (1998) in the journal *Nature.* This illusion relates to our feeling of ownership of our limbs, which we use to distinguish our limbs from other objects. The illusion also presents a procedure that is different from the “moving room” procedure of Lee and Aronson (1974) to establish the predominant place we give vision with respect 
to our other senses, especially proprioception and 
tactile sensation.

**The Illusion**

A person sits at a table while looking at a realistic life-size rubber hand on the tabletop. The person’s own hand is out of view, either placed under the table or covered by a screen. The experimenter uses two small paintbrushes to simultaneously brush the person’s hand and the rubber hand. An important part of creating the illusion is to synchronize the timing of the brushings. After several repeated brushings of the two hands, the person experiences the illusion that he or she can feel the brush strokes on the rubber hand as if it were his or her own. In fact, subjects have often spontaneously reported that the rubber hand feels like it is their own hand. Thus the pairing of the visual observation of the brushing of the rubber hand with the tactile sensation of the brushing of the real hand results in a perception that the visually observed rubber hand is part of the person. Interestingly, Botvinick and Cohen (1998) showed that part of the illusion involves a distortion of proprioceptive information when a moving of the rubber hand’s position gets reported by the person as a moving of his or her own hand.

**Brain Activity during the Illusion**

In their experiment Ehrsson and colleagues (2004) used fMRI to assess brain activity during the illusion experience. The results showed activation in the *prefrontal cortex,* which suggests that the mechanism underlying the feeling of limb ownership resides in this area of the brain, although other research has indicated the importance of the *parietal lobe* as well.

**cornea** a clear surface that covers the front of the eye; it serves as an important part of the eye’s optical system. **pupil** the opening in the eye that lets in light; its diameter increases and decreases according to the amount of light detected by the eye. 


**FIGURE 6.6** The human eye. *Source:* From Widmaier, E. P., Raff, H., & Strang, K. T. (2019). *Vander’s human physiology: The mechanisms of body function* (15th ed.). New York, NY: McGraw-Hill.

(a-b) Courtesy of Dr. Paul Milgram, Translucent Technologies, Inc., 
Toronto, Canada; (c) Nikom nik sunsopa/Shutterstock

**iris** the eye structure that surrounds the pupil and provides the eye its color. **lens** the transparent eye structure that sits just behind the iris; it allows the eye to focus at various distances. **retina** the eye structure that lines the back wall of the eye; as an extension of the brain it contains the neuroreceptors that transmit visual information to the brain.  **rods** one of two types of photoreceptors in the retina; they detect low levels of light and are important for peripheral vision. **cones** one of two types of photoreceptors in the retina; they detect bright light and play critical roles in central vision, visual acuity, and color vision.  **optic nerve** cranial nerve II; it serves as the means of information transmission from the retina to the brain. **optic chiasm** the place near the base of the brain where the optic nerve fibers meet and either continue to the same side or cross over to the opposite side of the brain. **visual field** the image or scene being viewed; it typically extends approximately 200 degrees horizontally and 160 degrees vertically. 


**FIGURE 6.7** The neural pathways for vision. *Source:* From Widmaier, E. P., Raff, H., & Strang, K. T. (2019). *Vander’s human physiology: The mechanisms of body function* (15th ed.). New York, NY: McGraw-Hill.

**FIGURE 6.8** The PLATO (Portable Liquid-Crystal Apparatus for Tachistoscopic Occlusion) visual occlusion spectacles in use to study the role of vision in ball catching; here the person can see the ball until it is near his hand and then his vision is occluded. The lenses are constructed with specially designed liquid crystal cells, which are powered by an electrical field applied across each lens. The lenses can change almost instantaneously from transparent to translucent (approximately 3–5 msec), which prevents the wearer from perceiving visual information, and from translucent to transparent (approximately 1 msec). *Source:* Courtesy of Dr. Paul Milgram, Translucent Technologies, Inc., Toronto, Canada (http: home.ca.inter.net/~milgram/plato.html); photograph by Avner Levona.

**FIGURE 6.9** An example of the event occlusion procedure: Examples of what subjects saw in the Abernethy and Russell experiment when they watched a film of a badminton serve where various parts of the serving action were masked and could not be seen. Note that in these frames, the occluded parts (i.e., “events”) of the server are (top row left to right): arm and racquet, racquet, ­(bottom row left to right): legs, head, a no-event control frame. *Source:* From Abernethy, B., & Russell, D. G. (1987). ­Expert-novice differences 
in an applied selective attention task. *Journal of Sport Psychology*, *9*, 326–345.

**A CLOSER LOOK**

**Peripheral Vision Provides Essential Information during a Discus Throw**

Two researchers in Belgium (Lenoir & Mazyn, 2005) studied ten experienced discus throwers to determine the visual contributions of central and peripheral vision during the throw. The throwers made throws with full vision, peripheral vision only, central vision only, and no vision. Results showed that throws were significantly shorter with only central and no vision available compared to throws with full and peripheral vision. These results demonstrate that peripheral vision provides essential information to allow the thrower to maintain control of the rotation of his or her body during the throw.

**central vision** the middle 2 to 5 degrees of the ­visual field; it is sometimes called *foveal* vision. **peripheral vision** the visual field outside the 2 to 5 degrees of central vision. **optical flow** the moving patterns of rays of light that strike the retina of the eye that emanate from and are specific to objects and features in the environment. 

**A CLOSER LOOK**

**The Use of Looming in Television and Movies: An Illustration of Our Use of** *Tau*

In their review of the issues related to determining the visual information people use to time the approach of an oncoming object, Abernethy and Burgess-­Limerick (1992) stated that if a *tau*-based method for picking up time to contact is viable, “observers must first and foremost be sensitive to information provided by optical expansion or ‘looming’” (p. 366). They went on to describe several research studies ­supporting this prediction. Although these studies are important to establish scientific support for *tau,* we can find evidence of our sensitivity to looming from a common everyday experience.

Have you ever watched a television program or movie and experienced the illusion of an object flying out of the screen directly at you? Because television and movies are two dimensional media, creators of ­visual effects implement the concept of looming to create the three dimensional quality of an object ­moving from far away and then acting as if it were flying out of the screen directly at the viewer. This illusion is created by making the object appear small on the screen and then having it nonlinearly expand in size (i.e., slowly at first and then rapidly). This change in the rate of expansion creates the optical illusion that the object will fly out of the screen and hit you. ­Undoubtedly you have observed this looming illusion, and have actually responded to it by moving your head to avoid the object hitting you. What is especially ­interesting about this behavioral reaction is that it ­occurs even though you know it is not possible for the object to physically fly out of the screen and hit you. The important point here is that the object made no distance and velocity changes; only size changed. It is this size-based change, and its nonlinear rate of expansion, that is the basis for *tau* providing a means for people to time the approach of an oncoming object.


**Specific Application Problem:**


You have been asked by your supervisor to evaluate the performance of a recent knee replacement patient. What would you expect to be the movement capabilities and limitations of this person who now has no joint receptors in the knee?

